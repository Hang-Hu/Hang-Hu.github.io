---
layout: post
author: Hang Hu
categories: python
tags: Blog Python 
cover: 
---
## Create DataFrame

```
tupleList.append((name, rank, area, profile, homepage))
df = pd.DataFrame(tupleList, columns=['name', 'rank', 'area', 'profile', 'homepage'])
```

### Create DataFrame with index

```
area_df = pd.DataFrame({'AREA': area_size.index, '# of Properties': area_size.values}, index=area_size.index)
```

## write dataframe to csv


```
df.to_csv('faculty_table.csv', header=True)
```


### to_csv no double quote


```
df.to_csv('foo.csv',header=True, index=False, quoting=csv.QUOTE_NONE)
```


### read csv


```
df = pd.read_csv('faculty_more_table.csv')
```


### add list to dataframe as column


```
df['research_interests'] = all_research_interests # all_research_interests is a list

```


### df column to list


```
profileList = df['profile'].tolist()
```


### Series get min index

size is a Series.

```
size.index.min()
```

### Axis start point

y axis start from 0, x axis starts from 1990

```
ax.set_ylim(bottom=0)
ax.set_xlim(left=1990)
```

### grid in chart

```
ax = size.plot()
ax.grid()
```

Or

```
size.plot(grid=True)
```

### Series to DataFrame

size is a Series.

```
size.head(3)

YEAR_BUILT
1900.0     40
1901.0    303
1902.0     15
dtype: int64
```

```
year_built_df = pd.DataFrame({'YEAR_BUILT': size.index, '# of Properties': size.values})
```

### Sort values in df

```
sort_df = year_built_df.sort_values('# of Properties', ascending=False)
```

### Series query with condition

```
size[size==size.min()]
size[size>2000]
```

### type of value in Series

x is a Series, so use `x[0]` and `type(x[0])`.

```
legal_df = df[['LEGAL_TYPE', 'CURRENT_PRICE', 'PREVIOUS_PRICE']].apply(lambda x: x if type(x[0]) is str else x/1e6)
```

### draw Probability density function of current price and previous price

```
price_df = df[['CURRENT_PRICE', 'PREVIOUS_PRICE']]
price_df = price_df.apply(lambda x: x/1e6)
price_df = price_df[(df.CURRENT_PRICE<=5e6) & (df.PREVIOUS_PRICE<=5e6)]
pdf_ax = price_df.plot.hist(bins=500, xlim=[0,5], alpha=0.5, grid=True)
pdf_ax.set_xlabel('Property Price (Million)')
pdf_ax.set_ylabel('# of Properties')
```

### Add Series to DataFrame

decrease_area_size is a Series with `AREA`(area code) as index, area_df also used area code as index, Series can be added to DataFrame based on the same index.

```
area_df = pd.DataFrame({'AREA': area_size.index, '# of Properties': area_size.values}, index=area_size.index)
area_df['# of Decreased Properties'] = decrease_area_size
```

### Series filter by condition

area_size is a Series.

```
area_size = area_size[area_size>=10]
```

### apply() on a column

Use `['PROPERTY_POSTAL_CODE']` before `.apply` to apply function only on a single column.

```
df['AREA'] = df['PROPERTY_POSTAL_CODE'].apply(lambda x: x[0:3])
```

### len of value in a column

To filter and leave only postal code with 7 characters(6 characters and 1 space in between).

```
df[df.PROPERTY_POSTAL_CODE.str.len()==7]
```

### filter out NaN

Use `dropna`.

```
df_sample_price = df_sample[['PREVIOUS_PRICE', 'CURRENT_PRICE']].dropna()
```

### count of row in DataFrame

`PREVIOUS_PRICE` is a column name.

```
df_sample.count()['PREVIOUS_PRICE']
```

### resample

Get resample the same size as the sample. Use `replace=True` otherwise it will return the same DataFrame with different order.

```
m = df_sample.sample(df_sample.count()['PREVIOUS_PRICE'], replace=True).median()
```

### dataframe change column to int

Type of column `YEAR_BUILT` was float64 at first.

```
sort_df = sort_df.astype({"YEAR_BUILT": int})
```

### select rows whose `PROPERTY_POSTAL_CODE` starts with `V6A`

Use `na=False` to remove `NaN` after `startswith`(some may not be string so `startswith` returns NaN), solve the error of `cannot index with vector containing NA / NaN values`.

```
df[df['PROPERTY_POSTAL_CODE'].str.startswith('V6A', na=False)]['PROPERTY_POSTAL_CODE']
```

### kind='scatter' plot

```
allyear_size = df.groupby('YEAR_BUILT').size()
allyear_df = pd.DataFrame({'YEAR_BUILT': allyear_size.index, '# of Properties': allyear_size.values})
ax = allyear_df[allyear_df['# of Properties']>2000].plot(kind='scatter', x='# of Properties', y='YEAR_BUILT')
ax.set_ylim(bottom=1900)
```

### 25th percentile for each year

I first group by year and then use quantile to calculate 25th percentile number for each year.

```
series_25th = houseDF.groupby('YEAR_BUILT')['HOUSE_PRICE'].quantile(0.25)
```

### Read mutiple json lines into DataFrame

```
pd.read_json('searchlog.json', lines=True)
```

### Association of 2 categories using chi-squared test

```
from scipy import stats

obs = pd.crosstab(searchDF['is_instructor'], searchDF['search_ui'])
print('===Contingency Table===\n', obs, '\n')
chi2_stat, p_val, dof, ex = stats.chi2_contingency(obs)
print('===Chi2 Stat===\n', chi2_stat, '\n')
print('===Degrees of Freedom===\n', dof, '\n')
print('===P-Value===\n', p_val, '\n')
sig = 0.01
if p_val<sig:
    print('Some association between the is_instructor and search_ui is present.')
else:
    print('There is no association between is_instructor and search_ui.')
```


[chisq](http://www.stat.yale.edu/Courses/1997-98/101/chisq.htm)

[scipy.stats.chi2_contingency](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chi2_contingency.html?highlight=contingency#scipy.stats.chi2_contingency)