## get features selected

`vectorizer.get_feature_names()` returns all features before selection.

```
from sklearn.datasets import fetch_20newsgroups
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.feature_selection import SelectKBest, chi2

data_train = fetch_20newsgroups(subset='train', categories=['comp.graphics','sci.space'],
                                shuffle=True, random_state=42,
                                remove=('headers', 'footers', 'quotes'))
vectorizer = TfidfVectorizer()
X = vectorizer.fit_transform(data_train.data)
y = data_train.target
kbest_model = SelectKBest(chi2, k=10)
X_new = kbest_model.fit_transform(X, y)
print(X_new.shape)
feature_names = vectorizer.get_feature_names()
top_10 = []
for index, is_selected in enumerate(kbest_model.get_support()):
    if is_selected:
        top_10.append(feature_names[index])
print(top_10)
```

## predict_proba array

```
prob_list = model.predict_proba(X_unlabeled)
```

It's probability of 2/more classifications: `model.classes_`

## logistic regression

```
from sklearn.linear_model import LogisticRegression

model = LogisticRegression(solver='liblinear')
model.fit(X, y)
prob_list = model.predict_proba(X_unlabeled)
```

## active learning uncertain sampling

Choose the most uncertain pair and label it, then retrain. Repeat 5 times.

```
from a9_utils import featurize, crowdsourcing
from sklearn.linear_model import LogisticRegression
import numpy as np

iter_num = 5
labeled_pairs = matches + nonmatches
unlabeled_pairs = [p for p in simpairs if p not in labeled_pairs]
    
def most_uncertain_pair_index(prob_list):
    diff_list = list(map(lambda x: abs(x[1]-x[0]), prob_list))
    return np.argmin(diff_list)

def model_training(iter_num, labeled_pairs, unlabeled_pairs):    
    for i in range(0, iter_num+1):
        print('{} iteration'.format(i))
        X = list(map(lambda x: featurize(x), labeled_pairs))
        y = [1] * len(matches) + [0] * len(nonmatches)
        model = LogisticRegression(solver='liblinear')
        model.fit(X, y)
        if i is iter_num:
            return model
        X_unlabeled = list(map(lambda x: featurize(x), unlabeled_pairs))
        prob_list = model.predict_proba(X_unlabeled)
        most_uncertain_pair = unlabeled_pairs[most_uncertain_pair_index(prob_list)]
        if crowdsourcing(most_uncertain_pair) is True:
            matches.append(most_uncertain_pair)
        else:
            nonmatches.append(most_uncertain_pair)
        labeled_pairs = matches + nonmatches
        unlabeled_pairs = [p for p in simpairs if p not in labeled_pairs]
    return model

model = model_training(iter_num, labeled_pairs, unlabeled_pairs)
```